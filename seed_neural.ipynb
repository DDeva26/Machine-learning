{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"seed_neural.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"dewqdsXNSr2u","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"722ZkzEOSxPG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":120},"outputId":"4a45c14d-0d6c-4b05-8bfa-37600c4ecfe6","executionInfo":{"status":"ok","timestamp":1587314150553,"user_tz":-330,"elapsed":28334,"user":{"displayName":"Arun Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giwy7jc0kkQBtE3YIb3YuSrtpgWAjkuwMPl6oXL=s64","userId":"13930642491105199669"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fdvSnwfbS_qN","colab_type":"code","colab":{}},"source":["os.chdir('/content/drive/My Drive/Colab Notebooks/MLLab/lab')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UuRjoeCpSr2x","colab_type":"code","colab":{}},"source":["df=pd.read_csv(\"seeds.csv\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2SIgdTPlTXU7","colab_type":"text"},"source":["10.The seeds dataset involves the prediction of species given measurements seeds from different varieties of wheat. There are 201 records and 7 numerical input variables. It is a classification problem with 3 output classes. The scale for each numeric input value vary, so some data normalization may be required for use with algorithms that weight inputs like the back propagation algorithm"]},{"cell_type":"code","metadata":{"id":"Ns8lhj5dSr20","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"outputId":"8dcbdcb9-e16b-46aa-d4d9-286cab8eb4e9","executionInfo":{"status":"ok","timestamp":1587314358606,"user_tz":-330,"elapsed":964,"user":{"displayName":"Arun Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giwy7jc0kkQBtE3YIb3YuSrtpgWAjkuwMPl6oXL=s64","userId":"13930642491105199669"}}},"source":["df.columns"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8'], dtype='object')"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"JrLcd5XOSr23","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":197},"outputId":"95d694c6-9be6-454d-81f1-06aa135aea25","executionInfo":{"status":"ok","timestamp":1587314359172,"user_tz":-330,"elapsed":812,"user":{"displayName":"Arun Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giwy7jc0kkQBtE3YIb3YuSrtpgWAjkuwMPl6oXL=s64","userId":"13930642491105199669"}}},"source":["df.head()"],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>V1</th>\n","      <th>V2</th>\n","      <th>V3</th>\n","      <th>V4</th>\n","      <th>V5</th>\n","      <th>V6</th>\n","      <th>V7</th>\n","      <th>V8</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>15.26</td>\n","      <td>14.84</td>\n","      <td>0.8710</td>\n","      <td>5.763</td>\n","      <td>3.312</td>\n","      <td>2.221</td>\n","      <td>5.220</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>14.88</td>\n","      <td>14.57</td>\n","      <td>0.8811</td>\n","      <td>5.554</td>\n","      <td>3.333</td>\n","      <td>1.018</td>\n","      <td>4.956</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>14.29</td>\n","      <td>14.09</td>\n","      <td>0.9050</td>\n","      <td>5.291</td>\n","      <td>3.337</td>\n","      <td>2.699</td>\n","      <td>4.825</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>13.84</td>\n","      <td>13.94</td>\n","      <td>0.8955</td>\n","      <td>5.324</td>\n","      <td>3.379</td>\n","      <td>2.259</td>\n","      <td>4.805</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>16.14</td>\n","      <td>14.99</td>\n","      <td>0.9034</td>\n","      <td>5.658</td>\n","      <td>3.562</td>\n","      <td>1.355</td>\n","      <td>5.175</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      V1     V2      V3     V4     V5     V6     V7  V8\n","0  15.26  14.84  0.8710  5.763  3.312  2.221  5.220   1\n","1  14.88  14.57  0.8811  5.554  3.333  1.018  4.956   1\n","2  14.29  14.09  0.9050  5.291  3.337  2.699  4.825   1\n","3  13.84  13.94  0.8955  5.324  3.379  2.259  4.805   1\n","4  16.14  14.99  0.9034  5.658  3.562  1.355  5.175   1"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"IB3e6eOzSr26","colab_type":"code","colab":{}},"source":["X=df.iloc[:,0:7].values\n","y=df.iloc[:,-1].values"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FRX_sp3SSr28","colab_type":"code","colab":{}},"source":["#splitiing the dataset into the Training set and test split\n","from sklearn.model_selection import train_test_split\n","X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7OnIkPaTSr2-","colab_type":"code","colab":{}},"source":["#feautre scaling important for deep learning\n","from sklearn.preprocessing import StandardScaler\n","sc=StandardScaler()\n","X_train=sc.fit_transform(X_train)\n","X_test=sc.transform(X_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WVmWpBfASr3B","colab_type":"code","colab":{}},"source":["#Part 2\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k6h29p2rSr3D","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"outputId":"e0b6ce00-0855-4f23-805d-cb34b6b2fbc9","executionInfo":{"status":"ok","timestamp":1587314368934,"user_tz":-330,"elapsed":1245,"user":{"displayName":"Arun Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giwy7jc0kkQBtE3YIb3YuSrtpgWAjkuwMPl6oXL=s64","userId":"13930642491105199669"}}},"source":["keras.initializers.Constant(value=0.5)"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<keras.initializers.Constant at 0x7f19acf2a208>"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"hwuUwO5LSr3H","colab_type":"code","colab":{}},"source":["#initializing the ANN\n","classifier=Sequential()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DO4fO09RSr3J","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"outputId":"54700d1a-ad91-44b9-b603-5d2592b85b03","executionInfo":{"status":"ok","timestamp":1587314372566,"user_tz":-330,"elapsed":698,"user":{"displayName":"Arun Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giwy7jc0kkQBtE3YIb3YuSrtpgWAjkuwMPl6oXL=s64","userId":"13930642491105199669"}}},"source":["#Adding the input layer and the first hidden layer\n","classifier.add(Dense(output_dim=4,init='uniform',activation='relu',input_dim=7))"],"execution_count":37,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=7, units=4, kernel_initializer=\"uniform\")`\n","  \"\"\"Entry point for launching an IPython kernel.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"OupcbmQxSr3L","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"outputId":"73e1d31f-cf17-4dff-bc6e-3189a9207f43","executionInfo":{"status":"ok","timestamp":1587314376940,"user_tz":-330,"elapsed":1109,"user":{"displayName":"Arun Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giwy7jc0kkQBtE3YIb3YuSrtpgWAjkuwMPl6oXL=s64","userId":"13930642491105199669"}}},"source":["#Adding the second hidden layer\n","classifier.add(Dense(output_dim=4,init='uniform',activation='relu'))"],"execution_count":38,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=4, kernel_initializer=\"uniform\")`\n","  \"\"\"Entry point for launching an IPython kernel.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"_vYFTktaSr3O","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"outputId":"99c42bba-5dd3-4a6d-83cc-0beded348a8c","executionInfo":{"status":"ok","timestamp":1587314383195,"user_tz":-330,"elapsed":1664,"user":{"displayName":"Arun Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giwy7jc0kkQBtE3YIb3YuSrtpgWAjkuwMPl6oXL=s64","userId":"13930642491105199669"}}},"source":["#Adding the output layer\n","classifier.add(Dense(output_dim=1,init='uniform',activation=\"sigmoid\"))"],"execution_count":39,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n","  \"\"\"Entry point for launching an IPython kernel.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ScAEQLj-Sr3Q","colab_type":"code","colab":{}},"source":["#compiling the ANN\n","#optimizer= adma is function that is give u gradient decent approach and it will reduce the error\n","classifier.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2gz21jR0Sr3S","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"12c24f47-f3ec-48bb-bd82-0a58ca961d88","executionInfo":{"status":"ok","timestamp":1587314392794,"user_tz":-330,"elapsed":6078,"user":{"displayName":"Arun Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giwy7jc0kkQBtE3YIb3YuSrtpgWAjkuwMPl6oXL=s64","userId":"13930642491105199669"}}},"source":["#fitting the ANN to the training set\n","classifier.fit(X_train,y_train,batch_size=10,nb_epoch=200)"],"execution_count":41,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n","  \"\"\"Entry point for launching an IPython kernel.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/200\n","168/168 [==============================] - 0s 629us/step - loss: 0.6811 - accuracy: 0.3393\n","Epoch 2/200\n","168/168 [==============================] - 0s 114us/step - loss: 0.6494 - accuracy: 0.3393\n","Epoch 3/200\n","168/168 [==============================] - 0s 113us/step - loss: 0.6051 - accuracy: 0.3393\n","Epoch 4/200\n","168/168 [==============================] - 0s 113us/step - loss: 0.5446 - accuracy: 0.3393\n","Epoch 5/200\n","168/168 [==============================] - 0s 113us/step - loss: 0.4514 - accuracy: 0.3393\n","Epoch 6/200\n","168/168 [==============================] - 0s 115us/step - loss: 0.3135 - accuracy: 0.3393\n","Epoch 7/200\n","168/168 [==============================] - 0s 109us/step - loss: 0.1246 - accuracy: 0.3393\n","Epoch 8/200\n","168/168 [==============================] - 0s 120us/step - loss: -0.1222 - accuracy: 0.3393\n","Epoch 9/200\n","168/168 [==============================] - 0s 112us/step - loss: -0.4428 - accuracy: 0.3393\n","Epoch 10/200\n","168/168 [==============================] - 0s 111us/step - loss: -0.8286 - accuracy: 0.3393\n","Epoch 11/200\n","168/168 [==============================] - 0s 132us/step - loss: -1.2859 - accuracy: 0.3393\n","Epoch 12/200\n","168/168 [==============================] - 0s 114us/step - loss: -1.8416 - accuracy: 0.3393\n","Epoch 13/200\n","168/168 [==============================] - 0s 119us/step - loss: -2.4641 - accuracy: 0.3393\n","Epoch 14/200\n","168/168 [==============================] - 0s 118us/step - loss: -3.1744 - accuracy: 0.3393\n","Epoch 15/200\n","168/168 [==============================] - 0s 113us/step - loss: -4.0253 - accuracy: 0.3393\n","Epoch 16/200\n","168/168 [==============================] - 0s 116us/step - loss: -4.9622 - accuracy: 0.3393\n","Epoch 17/200\n","168/168 [==============================] - 0s 125us/step - loss: -6.0067 - accuracy: 0.3393\n","Epoch 18/200\n","168/168 [==============================] - 0s 116us/step - loss: -7.2064 - accuracy: 0.3393\n","Epoch 19/200\n","168/168 [==============================] - 0s 115us/step - loss: -8.5507 - accuracy: 0.3393\n","Epoch 20/200\n","168/168 [==============================] - 0s 113us/step - loss: -10.0623 - accuracy: 0.3393\n","Epoch 21/200\n","168/168 [==============================] - 0s 114us/step - loss: -11.8046 - accuracy: 0.3393\n","Epoch 22/200\n","168/168 [==============================] - 0s 114us/step - loss: -13.6895 - accuracy: 0.3393\n","Epoch 23/200\n","168/168 [==============================] - 0s 113us/step - loss: -15.6897 - accuracy: 0.3393\n","Epoch 24/200\n","168/168 [==============================] - 0s 119us/step - loss: -18.0912 - accuracy: 0.3393\n","Epoch 25/200\n","168/168 [==============================] - 0s 113us/step - loss: -20.5416 - accuracy: 0.3393\n","Epoch 26/200\n","168/168 [==============================] - 0s 114us/step - loss: -23.3078 - accuracy: 0.3393\n","Epoch 27/200\n","168/168 [==============================] - 0s 116us/step - loss: -26.2704 - accuracy: 0.3393\n","Epoch 28/200\n","168/168 [==============================] - 0s 117us/step - loss: -29.5102 - accuracy: 0.3393\n","Epoch 29/200\n","168/168 [==============================] - 0s 124us/step - loss: -32.9433 - accuracy: 0.3393\n","Epoch 30/200\n","168/168 [==============================] - 0s 125us/step - loss: -36.5407 - accuracy: 0.3393\n","Epoch 31/200\n","168/168 [==============================] - 0s 122us/step - loss: -40.5834 - accuracy: 0.3393\n","Epoch 32/200\n","168/168 [==============================] - 0s 118us/step - loss: -44.9237 - accuracy: 0.3393\n","Epoch 33/200\n","168/168 [==============================] - 0s 112us/step - loss: -49.2460 - accuracy: 0.3393\n","Epoch 34/200\n","168/168 [==============================] - 0s 114us/step - loss: -54.2713 - accuracy: 0.3393\n","Epoch 35/200\n","168/168 [==============================] - 0s 125us/step - loss: -59.2857 - accuracy: 0.3393\n","Epoch 36/200\n","168/168 [==============================] - 0s 120us/step - loss: -64.7215 - accuracy: 0.3393\n","Epoch 37/200\n","168/168 [==============================] - 0s 123us/step - loss: -70.1893 - accuracy: 0.3393\n","Epoch 38/200\n","168/168 [==============================] - 0s 125us/step - loss: -76.3700 - accuracy: 0.3393\n","Epoch 39/200\n","168/168 [==============================] - 0s 130us/step - loss: -82.7435 - accuracy: 0.3393\n","Epoch 40/200\n","168/168 [==============================] - 0s 145us/step - loss: -89.2154 - accuracy: 0.3393\n","Epoch 41/200\n","168/168 [==============================] - 0s 133us/step - loss: -96.0998 - accuracy: 0.3393\n","Epoch 42/200\n","168/168 [==============================] - 0s 133us/step - loss: -103.6644 - accuracy: 0.3393\n","Epoch 43/200\n","168/168 [==============================] - 0s 120us/step - loss: -110.8613 - accuracy: 0.3393\n","Epoch 44/200\n","168/168 [==============================] - 0s 144us/step - loss: -118.9987 - accuracy: 0.3393\n","Epoch 45/200\n","168/168 [==============================] - 0s 122us/step - loss: -127.5875 - accuracy: 0.3393\n","Epoch 46/200\n","168/168 [==============================] - 0s 148us/step - loss: -135.7206 - accuracy: 0.3393\n","Epoch 47/200\n","168/168 [==============================] - 0s 155us/step - loss: -144.9226 - accuracy: 0.3393\n","Epoch 48/200\n","168/168 [==============================] - 0s 135us/step - loss: -153.9797 - accuracy: 0.3393\n","Epoch 49/200\n","168/168 [==============================] - 0s 145us/step - loss: -163.8765 - accuracy: 0.3393\n","Epoch 50/200\n","168/168 [==============================] - 0s 126us/step - loss: -174.0317 - accuracy: 0.3393\n","Epoch 51/200\n","168/168 [==============================] - 0s 145us/step - loss: -184.1196 - accuracy: 0.3393\n","Epoch 52/200\n","168/168 [==============================] - 0s 132us/step - loss: -195.3405 - accuracy: 0.3393\n","Epoch 53/200\n","168/168 [==============================] - 0s 143us/step - loss: -206.2001 - accuracy: 0.3393\n","Epoch 54/200\n","168/168 [==============================] - 0s 130us/step - loss: -217.8722 - accuracy: 0.3393\n","Epoch 55/200\n","168/168 [==============================] - 0s 190us/step - loss: -229.8309 - accuracy: 0.3393\n","Epoch 56/200\n","168/168 [==============================] - 0s 160us/step - loss: -242.4865 - accuracy: 0.3393\n","Epoch 57/200\n","168/168 [==============================] - 0s 146us/step - loss: -254.7264 - accuracy: 0.3393\n","Epoch 58/200\n","168/168 [==============================] - 0s 133us/step - loss: -268.5565 - accuracy: 0.3393\n","Epoch 59/200\n","168/168 [==============================] - 0s 136us/step - loss: -281.6799 - accuracy: 0.3393\n","Epoch 60/200\n","168/168 [==============================] - 0s 138us/step - loss: -295.9729 - accuracy: 0.3393\n","Epoch 61/200\n","168/168 [==============================] - 0s 171us/step - loss: -310.6794 - accuracy: 0.3393\n","Epoch 62/200\n","168/168 [==============================] - 0s 139us/step - loss: -325.5560 - accuracy: 0.3393\n","Epoch 63/200\n","168/168 [==============================] - 0s 142us/step - loss: -341.0752 - accuracy: 0.3393\n","Epoch 64/200\n","168/168 [==============================] - 0s 135us/step - loss: -356.4905 - accuracy: 0.3393\n","Epoch 65/200\n","168/168 [==============================] - 0s 145us/step - loss: -373.0494 - accuracy: 0.3393\n","Epoch 66/200\n","168/168 [==============================] - 0s 133us/step - loss: -390.0496 - accuracy: 0.3393\n","Epoch 67/200\n","168/168 [==============================] - 0s 131us/step - loss: -406.6836 - accuracy: 0.3393\n","Epoch 68/200\n","168/168 [==============================] - 0s 132us/step - loss: -424.1064 - accuracy: 0.3393\n","Epoch 69/200\n","168/168 [==============================] - 0s 126us/step - loss: -442.5032 - accuracy: 0.3393\n","Epoch 70/200\n","168/168 [==============================] - 0s 112us/step - loss: -460.9655 - accuracy: 0.3393\n","Epoch 71/200\n","168/168 [==============================] - 0s 112us/step - loss: -479.7043 - accuracy: 0.3393\n","Epoch 72/200\n","168/168 [==============================] - 0s 118us/step - loss: -498.8625 - accuracy: 0.3393\n","Epoch 73/200\n","168/168 [==============================] - 0s 121us/step - loss: -518.9888 - accuracy: 0.3393\n","Epoch 74/200\n","168/168 [==============================] - 0s 125us/step - loss: -539.4038 - accuracy: 0.3393\n","Epoch 75/200\n","168/168 [==============================] - 0s 135us/step - loss: -560.2690 - accuracy: 0.3393\n","Epoch 76/200\n","168/168 [==============================] - 0s 113us/step - loss: -581.7325 - accuracy: 0.3393\n","Epoch 77/200\n","168/168 [==============================] - 0s 116us/step - loss: -603.5621 - accuracy: 0.3393\n","Epoch 78/200\n","168/168 [==============================] - 0s 112us/step - loss: -625.7190 - accuracy: 0.3393\n","Epoch 79/200\n","168/168 [==============================] - 0s 116us/step - loss: -649.0730 - accuracy: 0.3393\n","Epoch 80/200\n","168/168 [==============================] - 0s 116us/step - loss: -672.3277 - accuracy: 0.3393\n","Epoch 81/200\n","168/168 [==============================] - 0s 114us/step - loss: -695.1385 - accuracy: 0.3393\n","Epoch 82/200\n","168/168 [==============================] - 0s 118us/step - loss: -720.1548 - accuracy: 0.3393\n","Epoch 83/200\n","168/168 [==============================] - 0s 111us/step - loss: -745.5699 - accuracy: 0.3393\n","Epoch 84/200\n","168/168 [==============================] - 0s 132us/step - loss: -770.1662 - accuracy: 0.3393\n","Epoch 85/200\n","168/168 [==============================] - 0s 128us/step - loss: -796.1186 - accuracy: 0.3393\n","Epoch 86/200\n","168/168 [==============================] - 0s 128us/step - loss: -822.2153 - accuracy: 0.3393\n","Epoch 87/200\n","168/168 [==============================] - 0s 130us/step - loss: -848.9441 - accuracy: 0.3393\n","Epoch 88/200\n","168/168 [==============================] - 0s 133us/step - loss: -876.9289 - accuracy: 0.3393\n","Epoch 89/200\n","168/168 [==============================] - 0s 129us/step - loss: -904.0459 - accuracy: 0.3393\n","Epoch 90/200\n","168/168 [==============================] - 0s 173us/step - loss: -933.0128 - accuracy: 0.3393\n","Epoch 91/200\n","168/168 [==============================] - 0s 122us/step - loss: -961.0082 - accuracy: 0.3393\n","Epoch 92/200\n","168/168 [==============================] - 0s 142us/step - loss: -990.8337 - accuracy: 0.3393\n","Epoch 93/200\n","168/168 [==============================] - 0s 137us/step - loss: -1020.5489 - accuracy: 0.3393\n","Epoch 94/200\n","168/168 [==============================] - 0s 133us/step - loss: -1051.6099 - accuracy: 0.3393\n","Epoch 95/200\n","168/168 [==============================] - 0s 120us/step - loss: -1082.2410 - accuracy: 0.3393\n","Epoch 96/200\n","168/168 [==============================] - 0s 122us/step - loss: -1112.9347 - accuracy: 0.3393\n","Epoch 97/200\n","168/168 [==============================] - 0s 113us/step - loss: -1145.6078 - accuracy: 0.3393\n","Epoch 98/200\n","168/168 [==============================] - 0s 136us/step - loss: -1178.4908 - accuracy: 0.3393\n","Epoch 99/200\n","168/168 [==============================] - 0s 126us/step - loss: -1211.5124 - accuracy: 0.3393\n","Epoch 100/200\n","168/168 [==============================] - 0s 117us/step - loss: -1245.6624 - accuracy: 0.3393\n","Epoch 101/200\n","168/168 [==============================] - 0s 116us/step - loss: -1279.1326 - accuracy: 0.3393\n","Epoch 102/200\n","168/168 [==============================] - 0s 132us/step - loss: -1313.4032 - accuracy: 0.3393\n","Epoch 103/200\n","168/168 [==============================] - 0s 119us/step - loss: -1349.3075 - accuracy: 0.3393\n","Epoch 104/200\n","168/168 [==============================] - 0s 118us/step - loss: -1385.7085 - accuracy: 0.3393\n","Epoch 105/200\n","168/168 [==============================] - 0s 118us/step - loss: -1421.6196 - accuracy: 0.3393\n","Epoch 106/200\n","168/168 [==============================] - 0s 115us/step - loss: -1459.2525 - accuracy: 0.3393\n","Epoch 107/200\n","168/168 [==============================] - 0s 119us/step - loss: -1496.7062 - accuracy: 0.3393\n","Epoch 108/200\n","168/168 [==============================] - 0s 118us/step - loss: -1535.2633 - accuracy: 0.3393\n","Epoch 109/200\n","168/168 [==============================] - 0s 123us/step - loss: -1572.4901 - accuracy: 0.3393\n","Epoch 110/200\n","168/168 [==============================] - 0s 121us/step - loss: -1612.1882 - accuracy: 0.3393\n","Epoch 111/200\n","168/168 [==============================] - 0s 132us/step - loss: -1652.4589 - accuracy: 0.3393\n","Epoch 112/200\n","168/168 [==============================] - 0s 120us/step - loss: -1693.2126 - accuracy: 0.3393\n","Epoch 113/200\n","168/168 [==============================] - 0s 117us/step - loss: -1733.4271 - accuracy: 0.3393\n","Epoch 114/200\n","168/168 [==============================] - 0s 116us/step - loss: -1775.0666 - accuracy: 0.3393\n","Epoch 115/200\n","168/168 [==============================] - 0s 113us/step - loss: -1816.6002 - accuracy: 0.3393\n","Epoch 116/200\n","168/168 [==============================] - 0s 126us/step - loss: -1861.2411 - accuracy: 0.3393\n","Epoch 117/200\n","168/168 [==============================] - 0s 125us/step - loss: -1902.4780 - accuracy: 0.3393\n","Epoch 118/200\n","168/168 [==============================] - 0s 116us/step - loss: -1946.6599 - accuracy: 0.3393\n","Epoch 119/200\n","168/168 [==============================] - 0s 130us/step - loss: -1992.1481 - accuracy: 0.3393\n","Epoch 120/200\n","168/168 [==============================] - 0s 131us/step - loss: -2036.4675 - accuracy: 0.3393\n","Epoch 121/200\n","168/168 [==============================] - 0s 129us/step - loss: -2081.9349 - accuracy: 0.3393\n","Epoch 122/200\n","168/168 [==============================] - 0s 133us/step - loss: -2127.8622 - accuracy: 0.3393\n","Epoch 123/200\n","168/168 [==============================] - 0s 139us/step - loss: -2174.8510 - accuracy: 0.3393\n","Epoch 124/200\n","168/168 [==============================] - 0s 134us/step - loss: -2221.7772 - accuracy: 0.3393\n","Epoch 125/200\n","168/168 [==============================] - 0s 127us/step - loss: -2270.4101 - accuracy: 0.3393\n","Epoch 126/200\n","168/168 [==============================] - 0s 122us/step - loss: -2319.2921 - accuracy: 0.3393\n","Epoch 127/200\n","168/168 [==============================] - 0s 115us/step - loss: -2367.7781 - accuracy: 0.3393\n","Epoch 128/200\n","168/168 [==============================] - 0s 119us/step - loss: -2417.8254 - accuracy: 0.3393\n","Epoch 129/200\n","168/168 [==============================] - 0s 119us/step - loss: -2468.8965 - accuracy: 0.3393\n","Epoch 130/200\n","168/168 [==============================] - 0s 111us/step - loss: -2520.2459 - accuracy: 0.3393\n","Epoch 131/200\n","168/168 [==============================] - 0s 120us/step - loss: -2569.3673 - accuracy: 0.3393\n","Epoch 132/200\n","168/168 [==============================] - 0s 117us/step - loss: -2624.3664 - accuracy: 0.3393\n","Epoch 133/200\n","168/168 [==============================] - 0s 122us/step - loss: -2676.8220 - accuracy: 0.3393\n","Epoch 134/200\n","168/168 [==============================] - 0s 186us/step - loss: -2729.4350 - accuracy: 0.3393\n","Epoch 135/200\n","168/168 [==============================] - 0s 169us/step - loss: -2783.4835 - accuracy: 0.3393\n","Epoch 136/200\n","168/168 [==============================] - 0s 126us/step - loss: -2835.8309 - accuracy: 0.3393\n","Epoch 137/200\n","168/168 [==============================] - 0s 128us/step - loss: -2892.9986 - accuracy: 0.3393\n","Epoch 138/200\n","168/168 [==============================] - 0s 161us/step - loss: -2950.0347 - accuracy: 0.3393\n","Epoch 139/200\n","168/168 [==============================] - 0s 131us/step - loss: -3004.9129 - accuracy: 0.3393\n","Epoch 140/200\n","168/168 [==============================] - 0s 136us/step - loss: -3061.5313 - accuracy: 0.3393\n","Epoch 141/200\n","168/168 [==============================] - 0s 145us/step - loss: -3119.5384 - accuracy: 0.3393\n","Epoch 142/200\n","168/168 [==============================] - 0s 128us/step - loss: -3177.6319 - accuracy: 0.3393\n","Epoch 143/200\n","168/168 [==============================] - 0s 151us/step - loss: -3236.8004 - accuracy: 0.3393\n","Epoch 144/200\n","168/168 [==============================] - 0s 139us/step - loss: -3295.8136 - accuracy: 0.3393\n","Epoch 145/200\n","168/168 [==============================] - 0s 140us/step - loss: -3354.3012 - accuracy: 0.3393\n","Epoch 146/200\n","168/168 [==============================] - 0s 133us/step - loss: -3416.8782 - accuracy: 0.3393\n","Epoch 147/200\n","168/168 [==============================] - 0s 131us/step - loss: -3478.3767 - accuracy: 0.3393\n","Epoch 148/200\n","168/168 [==============================] - 0s 147us/step - loss: -3540.0086 - accuracy: 0.3393\n","Epoch 149/200\n","168/168 [==============================] - 0s 145us/step - loss: -3600.6460 - accuracy: 0.3393\n","Epoch 150/200\n","168/168 [==============================] - 0s 153us/step - loss: -3663.9888 - accuracy: 0.3393\n","Epoch 151/200\n","168/168 [==============================] - 0s 131us/step - loss: -3730.1275 - accuracy: 0.3393\n","Epoch 152/200\n","168/168 [==============================] - 0s 166us/step - loss: -3793.2503 - accuracy: 0.3393\n","Epoch 153/200\n","168/168 [==============================] - 0s 153us/step - loss: -3858.9765 - accuracy: 0.3393\n","Epoch 154/200\n","168/168 [==============================] - 0s 123us/step - loss: -3923.9869 - accuracy: 0.3393\n","Epoch 155/200\n","168/168 [==============================] - 0s 111us/step - loss: -3992.3178 - accuracy: 0.3393\n","Epoch 156/200\n","168/168 [==============================] - 0s 126us/step - loss: -4058.4568 - accuracy: 0.3393\n","Epoch 157/200\n","168/168 [==============================] - 0s 112us/step - loss: -4125.8993 - accuracy: 0.3393\n","Epoch 158/200\n","168/168 [==============================] - 0s 112us/step - loss: -4191.9098 - accuracy: 0.3393\n","Epoch 159/200\n","168/168 [==============================] - 0s 114us/step - loss: -4264.8414 - accuracy: 0.3393\n","Epoch 160/200\n","168/168 [==============================] - 0s 124us/step - loss: -4332.1321 - accuracy: 0.3393\n","Epoch 161/200\n","168/168 [==============================] - 0s 121us/step - loss: -4403.9333 - accuracy: 0.3393\n","Epoch 162/200\n","168/168 [==============================] - 0s 117us/step - loss: -4473.4298 - accuracy: 0.3393\n","Epoch 163/200\n","168/168 [==============================] - 0s 115us/step - loss: -4544.0952 - accuracy: 0.3393\n","Epoch 164/200\n","168/168 [==============================] - 0s 116us/step - loss: -4617.4917 - accuracy: 0.3393\n","Epoch 165/200\n","168/168 [==============================] - 0s 115us/step - loss: -4690.8394 - accuracy: 0.3393\n","Epoch 166/200\n","168/168 [==============================] - 0s 115us/step - loss: -4761.4538 - accuracy: 0.3393\n","Epoch 167/200\n","168/168 [==============================] - 0s 115us/step - loss: -4838.4072 - accuracy: 0.3393\n","Epoch 168/200\n","168/168 [==============================] - 0s 127us/step - loss: -4911.1298 - accuracy: 0.3393\n","Epoch 169/200\n","168/168 [==============================] - 0s 116us/step - loss: -4984.2854 - accuracy: 0.3393\n","Epoch 170/200\n","168/168 [==============================] - 0s 131us/step - loss: -5062.5216 - accuracy: 0.3393\n","Epoch 171/200\n","168/168 [==============================] - 0s 123us/step - loss: -5139.4481 - accuracy: 0.3393\n","Epoch 172/200\n","168/168 [==============================] - 0s 119us/step - loss: -5212.7428 - accuracy: 0.3393\n","Epoch 173/200\n","168/168 [==============================] - 0s 123us/step - loss: -5289.0297 - accuracy: 0.3393\n","Epoch 174/200\n","168/168 [==============================] - 0s 115us/step - loss: -5367.5893 - accuracy: 0.3393\n","Epoch 175/200\n","168/168 [==============================] - 0s 115us/step - loss: -5449.0475 - accuracy: 0.3393\n","Epoch 176/200\n","168/168 [==============================] - 0s 107us/step - loss: -5527.8078 - accuracy: 0.3393\n","Epoch 177/200\n","168/168 [==============================] - 0s 117us/step - loss: -5606.0850 - accuracy: 0.3393\n","Epoch 178/200\n","168/168 [==============================] - 0s 114us/step - loss: -5688.3443 - accuracy: 0.3393\n","Epoch 179/200\n","168/168 [==============================] - 0s 120us/step - loss: -5768.7124 - accuracy: 0.3393\n","Epoch 180/200\n","168/168 [==============================] - 0s 154us/step - loss: -5850.1244 - accuracy: 0.3393\n","Epoch 181/200\n","168/168 [==============================] - 0s 118us/step - loss: -5933.9964 - accuracy: 0.3393\n","Epoch 182/200\n","168/168 [==============================] - 0s 120us/step - loss: -6012.4394 - accuracy: 0.3393\n","Epoch 183/200\n","168/168 [==============================] - 0s 112us/step - loss: -6098.5893 - accuracy: 0.3393\n","Epoch 184/200\n","168/168 [==============================] - 0s 110us/step - loss: -6182.5286 - accuracy: 0.3393\n","Epoch 185/200\n","168/168 [==============================] - 0s 136us/step - loss: -6270.5409 - accuracy: 0.3393\n","Epoch 186/200\n","168/168 [==============================] - 0s 133us/step - loss: -6352.4440 - accuracy: 0.3393\n","Epoch 187/200\n","168/168 [==============================] - 0s 141us/step - loss: -6439.6937 - accuracy: 0.3393\n","Epoch 188/200\n","168/168 [==============================] - 0s 129us/step - loss: -6527.8588 - accuracy: 0.3393\n","Epoch 189/200\n","168/168 [==============================] - 0s 131us/step - loss: -6614.9648 - accuracy: 0.3393\n","Epoch 190/200\n","168/168 [==============================] - 0s 147us/step - loss: -6703.5626 - accuracy: 0.3393\n","Epoch 191/200\n","168/168 [==============================] - 0s 127us/step - loss: -6793.5348 - accuracy: 0.3393\n","Epoch 192/200\n","168/168 [==============================] - 0s 135us/step - loss: -6884.5564 - accuracy: 0.3393\n","Epoch 193/200\n","168/168 [==============================] - 0s 136us/step - loss: -6972.2466 - accuracy: 0.3393\n","Epoch 194/200\n","168/168 [==============================] - 0s 154us/step - loss: -7063.9959 - accuracy: 0.3393\n","Epoch 195/200\n","168/168 [==============================] - 0s 132us/step - loss: -7158.9386 - accuracy: 0.3393\n","Epoch 196/200\n","168/168 [==============================] - 0s 151us/step - loss: -7249.6510 - accuracy: 0.3393\n","Epoch 197/200\n","168/168 [==============================] - 0s 135us/step - loss: -7342.8787 - accuracy: 0.3393\n","Epoch 198/200\n","168/168 [==============================] - 0s 152us/step - loss: -7437.9409 - accuracy: 0.3393\n","Epoch 199/200\n","168/168 [==============================] - 0s 132us/step - loss: -7532.1342 - accuracy: 0.3393\n","Epoch 200/200\n","168/168 [==============================] - 0s 124us/step - loss: -7626.9556 - accuracy: 0.3393\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.callbacks.History at 0x7f19acf2a860>"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"PLT23yifSr3U","colab_type":"code","colab":{}},"source":["#part 3- making the prediction and evaluating the model\n","#predicting the test set results\n","y_pred=classifier.predict(X_test)\n","y_pred=(y_pred>0.5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"59Kp5v45Sr3V","colab_type":"code","colab":{}},"source":["#Making the confusion matrix\n","from sklearn.metrics import confusion_matrix\n","cm=confusion_matrix(y_test,y_pred)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1HmPzfO0Sr3X","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"outputId":"ed7ee9f1-2d6a-4069-8118-39ee0165fa68","executionInfo":{"status":"ok","timestamp":1587314399388,"user_tz":-330,"elapsed":1079,"user":{"displayName":"Arun Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giwy7jc0kkQBtE3YIb3YuSrtpgWAjkuwMPl6oXL=s64","userId":"13930642491105199669"}}},"source":["from sklearn.metrics import accuracy_score\n","accuracy_score(y_test,y_pred)"],"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.30952380952380953"]},"metadata":{"tags":[]},"execution_count":44}]}]}